{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import joblib\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlertModel(object):\n",
    "    \n",
    "    def __init__(self, data, delta = 3600, lifetime = 60*60*24):\n",
    "        self.data = data\n",
    "        \n",
    "        # внутренний счетчик времени в формате timestamp, нужно проинициализировать минимальной датой-временем в data        \n",
    "        self.startTime = self.time = data.date.values.min()        \n",
    "        self.lastTime = data.date.values.max()        \n",
    "        \n",
    "        # delta - какой инкремент к внутреннему времени модель делает за один тик:\n",
    "        self.delta = delta\n",
    "        \n",
    "        self.lifetime = lifetime\n",
    "        self.inc = 0\n",
    "        \n",
    "        self.itera = 1\n",
    "        self.anomaly = False\n",
    "        self.history = [[[] for j in range(4)] for i in range(7)]\n",
    "        self.dayOfWeek = self._getDayOfWeek()\n",
    "        self.dayTime = self._getDayTime()\n",
    "        self.history[self.dayOfWeek][self.dayTime].append(0)\n",
    "        \n",
    "        \n",
    "    '''\n",
    "        Функция вычисляет центр кластера точек с географическими координатами. \n",
    "        Аргументы : координаты кластера, массив (массив, список списков и т. д.), n - количество точек (широта, долгота) в кластере.\n",
    "        Возвращает:  геометрический центр кластера \n",
    "    '''\n",
    "    def get_centroid(self, cluster):\n",
    "        cluster_ary = np.asarray(cluster)\n",
    "        centroid = cluster_ary.mean(axis = 0)\n",
    "        return centroid\n",
    "    \n",
    "    \n",
    "    def build_dbscan_model(self, df):\n",
    "        if len(df) > 1:\n",
    "            kms_per_rad = 6371.0088\n",
    "            epsilon = 1.5/kms_per_rad\n",
    "\n",
    "            # Извлекаем ширину и долготу\n",
    "            fac_coords = df[['latitude', 'longitude']].values\n",
    "\n",
    "            start_time = time.time()\n",
    "            dbsc = (DBSCAN(eps=epsilon, min_samples=1, algorithm='ball_tree', metric='haversine')\n",
    "                    .fit(np.radians(fac_coords)))\n",
    "            fac_cluster_labels = dbsc.labels_\n",
    "\n",
    "            # получаем количеств кластеров\n",
    "            num_clusters = len(set(dbsc.labels_))\n",
    "            if num_clusters > 1:\n",
    "                message = 'Кластеризировано {:,} точек на {:,} кластеров, с сжатием {:.1f}% в {:,.2f} секундах'\n",
    "                #print(message.format(len(df), num_clusters, 100*(1 - float(num_clusters) / len(df)), time.time()-start_time))\n",
    "                if len(df) > num_clusters:\n",
    "                    print('/n')\n",
    "                   # print('Silhouette coefficient: {:0.03f}'.format(metrics.silhouette_score(fac_coords, fac_cluster_labels)))\n",
    "                else:\n",
    "                    return False\n",
    "                dbsc_clusters = pd.Series([fac_coords[fac_cluster_labels==n] for n in range(num_clusters)])\n",
    "    \n",
    "                # получить центр каждого кластера\n",
    "                fac_centroids = dbsc_clusters.map(self.get_centroid)\n",
    "\n",
    "                cent_lats, cent_lons = zip(*fac_centroids)\n",
    "                centroids_pd = pd.DataFrame({'longitude':cent_lons, 'latitude':cent_lats, 'power': len(df)})\n",
    "                self.make_json(df, centroids_pd, fac_cluster_labels)\n",
    "                return centroids_pd\n",
    "            else:\n",
    "                return num_clusters\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "        \n",
    "    def make_json(self, df, cen_pd, fac_cluster_labels):\n",
    "        a = []\n",
    "        json_data = {}\n",
    "        b = []\n",
    "        c = 0\n",
    "        json_data[\"incident\"] = {}\n",
    "        json_data[\"cluster\"] = {}\n",
    "        m = len(df)\n",
    "        for index, row in df.iterrows():\n",
    "            if m>=c:\n",
    "                a.append({'id' : int(row['index']),\n",
    "                         'date': int(row['date']),\n",
    "                          'latitude': row['latitude'],\n",
    "                          'longitude' : row['longitude'],\n",
    "                          'area' : row['area'],\n",
    "                          'category':row['category'],\n",
    "                          'cluster_id': int(fac_cluster_labels[c])\n",
    "                         })\n",
    "                c += 1\n",
    "        json_data[\"incident\"] = a  \n",
    "        for index, row in cen_pd.iterrows():\n",
    "            b.append({'id' : int(index),\n",
    "                     'latitude': cen_pd.latitude.iloc[index] ,\n",
    "                      'longitude': cen_pd.longitude.iloc[index] ,\n",
    "                      'power' : int(cen_pd.power.iloc[index]),\n",
    "                     })\n",
    "        json_data[\"cluster\"] = b\n",
    "        \n",
    "        if self.anomaly != False:\n",
    "            print(self.anomaly)\n",
    "            json_data[\"anomaly\"] = self.anomaly\n",
    "            \n",
    "        j = json.dumps(json_data,indent = 5, ensure_ascii=False)\n",
    "        with open(\"iterations/iteration\" + str(self.itera) +\".json\", \"w\") as write_file:\n",
    "            json.dump(json_data, write_file)\n",
    "        self.itera += 1\n",
    "\n",
    "    \n",
    "        \n",
    "    def _getDayOfWeek(self):\n",
    "        return dt.datetime.fromtimestamp(self.time).weekday()\n",
    "    \n",
    "    def _getDayTime(self):\n",
    "        return int(dt.datetime.fromtimestamp(self.time).hour // (24/4))\n",
    "    \n",
    "    def _detectAnomaly(self):\n",
    "        data = self.history[self.dayOfWeek][self.dayTime]\n",
    "        if len(data) < 10:\n",
    "            self.anomaly = False\n",
    "            return False  # недостаточно данных для постановки статистического эксперимента\n",
    "        else:\n",
    "            #if data[-2] > np.percentile(data[:-2], 99):\n",
    "            if data[-2] > np.array(data[:-2]).mean() + np.array(data[:-2]).var():\n",
    "                self.anomaly = {\n",
    "                    \"caption\": 'Статистически значимое превышение',\n",
    "                    \"disp\": np.array(data[:-2]).var(),\n",
    "                    \"history\": data[:-2],\n",
    "                    \"value\": data[-2]\n",
    "                }\n",
    "                return True\n",
    "            else:\n",
    "                self.anomaly = False\n",
    "                return False\n",
    "       \n",
    "   # итерирует модель на 1 дискрет времени относительно внутреннего времени time\n",
    "    def iterate(self):\n",
    "        # Итерирует модель на 1 дискрет времени\n",
    "        currentIncidentsDf = self.data[(self.data.date >= self.time - self.lifetime) & (self.data.date < self.time + self.delta)]               \n",
    "        \n",
    "        if self.dayOfWeek == self._getDayOfWeek() or self.dayTime == self._getDayTime():\n",
    "            self._detectAnomaly()  # накопились данные для постановки статистического эксперимента\n",
    "        else:\n",
    "            self.dayOfWeek = self._getDayOfWeek()\n",
    "            self.dayTime = self._getDayTime()\n",
    "            self.history[self.dayOfWeek][self.dayTime].append(0)\n",
    "              \n",
    "        incidentsCount = len(self.data[(self.data.date >= self.time) & (self.data.date < self.time + self.delta)])\n",
    "        self.history[self.dayOfWeek][self.dayTime][-1] += incidentsCount\n",
    "        \n",
    "        self.time += self.delta\n",
    "        self.inc += 1\n",
    "\n",
    "        return currentIncidentsDf\n",
    "    \n",
    "    \n",
    "    # итерирует модель до момента timestamp (если не задан - то до текущего момента времени)\n",
    "    def iterateTo(self, timestamp = int(time.mktime(dt.datetime.now().timetuple()))):\n",
    "        i = 0\n",
    "        while self.time < min(timestamp, self.lastTime):\n",
    "            res = self.iterate()\n",
    "            model_dbscan = self.build_dbscan_model(res)\n",
    "            if i % 100 == 0:\n",
    "                print('\\n', dt.datetime.fromtimestamp(self.time), len(res))\n",
    "            #else:\n",
    "             #   print(' ', end = '')\n",
    "            i += 1\n",
    "        return True # если итерации прошли успешно возвращает True, иначе False\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данные для анализа\n",
    "df = pd.read_csv('data/Датасет4_Пожары.xlsx - mess_АпкБг1016Пожары.csv')\n",
    "df.reset_index(level=0, inplace=True)\n",
    "\n",
    "df.columns = ['index', 'registration_time', 'category', 'id_addres', 'id_building', 'latitude', 'longitude', 'area']\n",
    "data = df[['index', 'registration_time', 'latitude', 'longitude', 'category', 'area']]\n",
    "data = data[data['latitude'] != 0]\n",
    "data = data[data['longitude'] < 45]\n",
    "# Преобразовать в unix timestamp:\n",
    "data['registration_time'] = pd.to_datetime(df['registration_time'])\n",
    "data['date'] = pd.to_datetime(df['registration_time']).astype(int)/ 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2019-01-01 03:07:00 1\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "\n",
      " 2019-01-01 04:47:00 30\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "\n",
      " 2019-01-01 06:27:00 39\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "\n",
      " 2019-01-01 08:07:00 42\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "\n",
      " 2019-01-01 09:47:00 50\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "\n",
      " 2019-01-01 11:27:00 53\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "\n",
      " 2019-01-01 13:07:00 54\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "\n",
      " 2019-01-01 14:47:00 56\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n",
      "/n\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-3b90a02ebbbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlertModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterateTo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-170-00b29a4993c7>\u001b[0m in \u001b[0;36miterateTo\u001b[0;34m(self, timestamp)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlastTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mmodel_dbscan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dbscan_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-170-00b29a4993c7>\u001b[0m in \u001b[0;36mbuild_dbscan_model\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             dbsc = (DBSCAN(eps=epsilon, min_samples=1, algorithm='ball_tree', metric='haversine')\n\u001b[0m\u001b[1;32m     45\u001b[0m                     .fit(np.radians(fac_coords)))\n\u001b[1;32m     46\u001b[0m             \u001b[0mfac_cluster_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# ignore first 'self' argument for instance methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = AlertModel(data)\n",
    "\n",
    "model.iterateTo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[], [], [], []],\n",
       " [[57], [], [], []],\n",
       " [[], [], [], []],\n",
       " [[], [], [], []],\n",
       " [[], [], [], []],\n",
       " [[], [], [], []],\n",
       " [[], [], [], []]]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group = data.groupby([data['registration_time'].dt.date])['date'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type datetime.datetime)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b6ee80ddad98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweekday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type datetime.datetime)"
     ]
    }
   ],
   "source": [
    "dt.datetime.fromtimestamp(dt.datetime.now()).weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 11, 14, 13, 49, 20, 46440)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
