{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель выявления нештатных ситуаций в жизнедеятельности города на основании сообщений жителей, поступающих в режиме реального времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import joblib\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель на вход принимает параметры сообщения о происшествиях, сдвиг по времени, время жизни данных которые обрабатываются.\n",
    "\n",
    "На выход модель отдает данные в формате json: о происшествиях, к какому кластеру они относятся и аномалиях.\n",
    "\n",
    "Для кластеризации данных был выбран алгоритм DBSCAN.\n",
    "\n",
    "Преимущества:\n",
    "1. Не требует заранее указывать количество кластеров.\n",
    "2. Хорошо работает с кластерами произвольной формы.\n",
    "3. DBSCAN устойчив к выбросам и способен обнаруживать выбросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlertModel(object):\n",
    "    \n",
    "    def __init__(self, data, delta = 3600, lifetime = 60*60*24):\n",
    "        self.data = data\n",
    "        \n",
    "        # внутренний счетчик времени в формате timestamp, нужно проинициализировать минимальной датой-временем в data        \n",
    "        self.startTime = self.time = data.date.values.min()        \n",
    "        self.lastTime = data.date.values.max()        \n",
    "        \n",
    "        # delta - какой инкремент к внутреннему времени модель делает за один тик:\n",
    "        self.delta = delta\n",
    "        \n",
    "        self.lifetime = lifetime\n",
    "        self.inc = 0\n",
    "        \n",
    "        self.itera = 1\n",
    "        self.anomaly = False\n",
    "        self.history = [[[] for j in range(4)] for i in range(7)]\n",
    "        self.dayOfWeek = self._getDayOfWeek()\n",
    "        self.dayTime = self._getDayTime()\n",
    "        self.history[self.dayOfWeek][self.dayTime].append(0)\n",
    "        \n",
    "        \n",
    "    '''\n",
    "        Функция вычисляет центр кластера точек с географическими координатами. \n",
    "        Аргументы : координаты кластера, массив (массив, список списков и т. д.), n - количество точек (широта, долгота) в кластере.\n",
    "        Возвращает:  геометрический центр кластера \n",
    "    '''\n",
    "    def get_centroid(self, cluster):\n",
    "        cluster_ary = np.asarray(cluster)\n",
    "        centroid = cluster_ary.mean(axis = 0)\n",
    "        return centroid\n",
    "    \n",
    "    \n",
    "    def build_dbscan_model(self, df):\n",
    "        if len(df) > 1:\n",
    "            kms_per_rad = 6371.0088\n",
    "            epsilon = 1.5/kms_per_rad\n",
    "\n",
    "            # Извлекаем ширину и долготу\n",
    "            fac_coords = df[['latitude', 'longitude']].values\n",
    "\n",
    "            start_time = time.time()\n",
    "            dbsc = (DBSCAN(eps=epsilon, min_samples=1, algorithm='ball_tree', metric='haversine')\n",
    "                    .fit(np.radians(fac_coords)))\n",
    "            fac_cluster_labels = dbsc.labels_\n",
    "\n",
    "            # получаем количеств кластеров\n",
    "            num_clusters = len(set(dbsc.labels_))\n",
    "            if num_clusters > 1:\n",
    "                message = 'Кластеризировано {:,} точек на {:,} кластеров, с сжатием {:.1f}% в {:,.2f} секундах'\n",
    "                #print(message.format(len(df), num_clusters, 100*(1 - float(num_clusters) / len(df)), time.time()-start_time))\n",
    "                #if len(df) > num_clusters:\n",
    "                #    print('/n')\n",
    "                #    print('Silhouette coefficient: {:0.03f}'.format(metrics.silhouette_score(fac_coords, fac_cluster_labels)))\n",
    "                #else:\n",
    "                #    return False\n",
    "                dbsc_clusters = pd.Series([fac_coords[fac_cluster_labels==n] for n in range(num_clusters)])\n",
    "    \n",
    "                # получить центр каждого кластера\n",
    "                fac_centroids = dbsc_clusters.map(self.get_centroid)\n",
    "\n",
    "                cent_lats, cent_lons = zip(*fac_centroids)\n",
    "                centroids_pd = pd.DataFrame({'longitude':cent_lons, 'latitude':cent_lats, 'power': len(df)})\n",
    "                self.make_json(df, centroids_pd, fac_cluster_labels)\n",
    "                return centroids_pd\n",
    "            else:\n",
    "                return num_clusters\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    \n",
    "    # Функция создает json файлы для каждой итерации,\n",
    "    # в котором содержится информация о происшествии, кластере к которму оно принадлежит и аномалиях.\n",
    "    def make_json(self, df, cen_pd, fac_cluster_labels):\n",
    "        a = []\n",
    "        json_data = {}\n",
    "        b = []\n",
    "        c = 0\n",
    "        json_data[\"incident\"] = {}\n",
    "        json_data[\"cluster\"] = {}\n",
    "        m = len(df)\n",
    "        for index, row in df.iterrows():\n",
    "            if m>=c:\n",
    "                a.append({'id' : int(row['index']),\n",
    "                         'date': int(row['date']),\n",
    "                          'latitude': row['latitude'],\n",
    "                          'longitude' : row['longitude'],\n",
    "                          'area' : row['area'],\n",
    "                          'category':row['category'],\n",
    "                          'cluster_id': int(fac_cluster_labels[c])\n",
    "                         })\n",
    "                c += 1\n",
    "        json_data[\"incident\"] = a  \n",
    "        for index, row in cen_pd.iterrows():\n",
    "            b.append({'id' : int(index),\n",
    "                     'latitude': cen_pd.latitude.iloc[index] ,\n",
    "                      'longitude': cen_pd.longitude.iloc[index] ,\n",
    "                      'power' : int(cen_pd.power.iloc[index]),\n",
    "                     })\n",
    "        json_data[\"cluster\"] = b\n",
    "        \n",
    "        if self.anomaly != False:\n",
    "            print(self.anomaly)\n",
    "            json_data[\"anomaly\"] = self.anomaly\n",
    "            \n",
    "        j = json.dumps(json_data,indent = 5, ensure_ascii=False)\n",
    "        with open(\"iterations/iteration\" + str(self.itera) +\".json\", \"w\") as write_file:\n",
    "            json.dump(json_data, write_file)\n",
    "        self.itera += 1\n",
    "\n",
    "        \n",
    "    def _getDayOfWeek(self):\n",
    "        return dt.datetime.fromtimestamp(self.time).weekday()\n",
    "    \n",
    "    \n",
    "    def _getDayTime(self):\n",
    "        return int(dt.datetime.fromtimestamp(self.time).hour // (24/4))\n",
    "    \n",
    "    \n",
    "    #Функция выявления аномалий текущего количество обращений в городские службы по одному из двух критериев: \n",
    "    # 1. отклонение от среднего больше чем на дисперсию;\n",
    "    # 2. выход значений 99 перцентиль по истории фиксации.\n",
    "    def _detectAnomaly(self):\n",
    "        data = self.history[self.dayOfWeek][self.dayTime]\n",
    "        if len(data) < 5:\n",
    "            self.anomaly = False\n",
    "            return False  # недостаточно данных для постановки статистического эксперимента\n",
    "        else:\n",
    "            #if data[-2] > np.percentile(data[:-2], 99):\n",
    "            if data[-2] > np.array(data[:-2]).mean() + np.array(data[:-2]).var():\n",
    "                self.anomaly = {\n",
    "                    \"caption\": 'Статистически значимое превышение',\n",
    "                    \"disp\": np.array(data[:-2]).var(),\n",
    "                    \"history\": data[:-2],\n",
    "                    \"value\": data[-2]\n",
    "                }\n",
    "                return True\n",
    "            else:\n",
    "                self.anomaly = False\n",
    "                return False\n",
    "       \n",
    "    # Функиция итерирует модель на 1 дискрет времени относительно внутреннего времени time\n",
    "    def iterate(self):\n",
    "        # Итерирует модель на 1 дискрет времени\n",
    "        currentIncidentsDf = self.data[(self.data.date >= self.time - self.lifetime) & (self.data.date < self.time + self.delta)]               \n",
    "        \n",
    "        if self.dayOfWeek == self._getDayOfWeek() or self.dayTime == self._getDayTime():\n",
    "            self._detectAnomaly()  # накопились данные для постановки статистического эксперимента\n",
    "        else:\n",
    "            self.dayOfWeek = self._getDayOfWeek()\n",
    "            self.dayTime = self._getDayTime()\n",
    "            self.history[self.dayOfWeek][self.dayTime].append(0)\n",
    "              \n",
    "        incidentsCount = len(self.data[(self.data.date >= self.time) & (self.data.date < self.time + self.delta)])\n",
    "        self.history[self.dayOfWeek][self.dayTime][-1] += incidentsCount\n",
    "        \n",
    "        self.time += self.delta\n",
    "        self.inc += 1\n",
    "\n",
    "        return currentIncidentsDf\n",
    "    \n",
    "    \n",
    "    # Функиция итерирует модель до момента timestamp (если не задан - то до текущего момента времени)\n",
    "    def iterateTo(self, timestamp = int(time.mktime(dt.datetime.now().timetuple()))):\n",
    "        i = 0\n",
    "        while self.time < min(timestamp, self.lastTime):\n",
    "            res = self.iterate()\n",
    "            model_dbscan = self.build_dbscan_model(res)\n",
    "            if i % 100 == 0:\n",
    "                print('\\n', dt.datetime.fromtimestamp(self.time), len(res))\n",
    "            #else:\n",
    "             #   print(' ', end = '')\n",
    "            i += 1\n",
    "        return True # если итерации прошли успешно возвращает True, иначе False\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-7f34ede75e48>:12: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  data['date'] = [int((dt - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')) for dt in pd.to_datetime(data['registration_time']).values]\n"
     ]
    }
   ],
   "source": [
    "# Данные для анализа\n",
    "df = pd.read_csv('data/Датасет4_Пожары.xlsx - mess_АпкБг1016Пожары.csv')\n",
    "df.reset_index(level=0, inplace=True)\n",
    "\n",
    "df.columns = ['index', 'registration_time', 'category', 'id_addres', 'id_building', 'latitude', 'longitude', 'area']\n",
    "data = df[['index', 'registration_time', 'latitude', 'longitude', 'category', 'area']]\n",
    "data = data[data['latitude'] != 0]\n",
    "data = data[data['longitude'] < 45]\n",
    "# Преобразовать в unix timestamp:\n",
    "data['registration_time'] = pd.to_datetime(df['registration_time'])\n",
    "# data['date'] = pd.to_datetime(data['registration_time']).astype(int)/ 10**9\n",
    "data['date'] = [int((dt - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')) for dt in pd.to_datetime(data['registration_time']).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2019-01-01 04:06:00 12\n",
      "\n",
      " 2019-01-05 08:06:00 31\n",
      "\n",
      " 2019-01-09 12:06:00 31\n",
      "\n",
      " 2019-01-13 16:06:00 38\n",
      "\n",
      " 2019-01-17 20:06:00 59\n",
      "\n",
      " 2019-01-22 00:06:00 55\n",
      "\n",
      " 2019-01-26 04:06:00 60\n",
      "\n",
      " 2019-01-30 08:06:00 60\n",
      "\n",
      " 2019-02-03 12:06:00 59\n",
      "\n",
      " 2019-02-07 16:06:00 62\n",
      "\n",
      " 2019-02-11 20:06:00 43\n",
      "\n",
      " 2019-02-16 00:06:00 40\n",
      "\n",
      " 2019-02-20 04:06:00 35\n",
      "\n",
      " 2019-02-24 08:06:00 35\n",
      "\n",
      " 2019-02-28 12:06:00 39\n",
      "\n",
      " 2019-03-04 16:06:00 75\n",
      "\n",
      " 2019-03-08 20:06:00 48\n",
      "\n",
      " 2019-03-13 00:06:00 31\n",
      "\n",
      " 2019-03-17 04:06:00 48\n",
      "\n",
      " 2019-03-21 08:06:00 13\n",
      "\n",
      " 2019-03-25 12:06:00 58\n",
      "\n",
      " 2019-03-29 16:06:00 50\n",
      "\n",
      " 2019-04-02 20:06:00 44\n",
      "\n",
      " 2019-04-07 00:06:00 91\n",
      "\n",
      " 2019-04-11 04:06:00 50\n",
      "\n",
      " 2019-04-15 08:06:00 85\n",
      "\n",
      " 2019-04-19 12:06:00 109\n",
      "\n",
      " 2019-04-23 16:06:00 70\n",
      "\n",
      " 2019-04-27 20:06:00 117\n",
      "\n",
      " 2019-05-02 00:06:00 98\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 29.95918367346939, 'history': [33, 40, 40, 35, 30, 23, 34], 'value': 75}\n",
      "\n",
      " 2019-05-06 04:06:00 47\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 21.609375, 'history': [32, 23, 27, 33, 31, 21, 31, 35], 'value': 52}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "{'caption': 'Статистически значимое превышение', 'disp': 82.4375, 'history': [53, 67, 76, 44, 54, 54, 59, 59], 'value': 151}\n",
      "\n",
      " 2019-05-10 08:06:00 74\n",
      "\n",
      " 2019-05-14 12:06:00 56\n",
      "\n",
      " 2019-05-18 16:06:00 59\n",
      "\n",
      " 2019-05-22 20:06:00 49\n",
      "\n",
      " 2019-05-27 00:06:00 57\n",
      "\n",
      " 2019-05-31 04:06:00 53\n",
      "\n",
      " 2019-06-04 08:06:00 78\n",
      "\n",
      " 2019-06-08 12:06:00 57\n",
      "\n",
      " 2019-06-12 16:06:00 66\n",
      "\n",
      " 2019-06-16 20:06:00 60\n",
      "\n",
      " 2019-06-21 00:06:00 73\n",
      "\n",
      " 2019-06-25 04:06:00 78\n",
      "\n",
      " 2019-06-29 08:06:00 53\n",
      "\n",
      " 2019-07-03 12:06:00 44\n",
      "\n",
      " 2019-07-07 16:06:00 57\n",
      "\n",
      " 2019-07-11 20:06:00 40\n",
      "\n",
      " 2019-07-16 00:06:00 32\n",
      "\n",
      " 2019-07-20 04:06:00 42\n",
      "\n",
      " 2019-07-24 08:06:00 51\n",
      "\n",
      " 2019-07-28 12:06:00 55\n",
      "\n",
      " 2019-08-01 16:06:00 44\n",
      "\n",
      " 2019-08-05 20:06:00 53\n",
      "\n",
      " 2019-08-10 00:06:00 67\n",
      "\n",
      " 2019-08-14 04:06:00 68\n",
      "\n",
      " 2019-08-18 08:06:00 74\n",
      "\n",
      " 2019-08-22 12:06:00 48\n",
      "\n",
      " 2019-08-26 16:06:00 49\n",
      "\n",
      " 2019-08-30 20:06:00 60\n",
      "\n",
      " 2019-09-04 00:06:00 25\n",
      "\n",
      " 2019-09-08 04:06:00 71\n",
      "\n",
      " 2019-09-12 08:06:00 41\n",
      "\n",
      " 2019-09-16 12:06:00 67\n",
      "\n",
      " 2019-09-20 16:06:00 49\n",
      "\n",
      " 2019-09-24 20:06:00 52\n",
      "\n",
      " 2019-09-29 00:06:00 53\n",
      "\n",
      " 2019-10-03 04:06:00 36\n",
      "\n",
      " 2019-10-07 08:06:00 49\n",
      "\n",
      " 2019-10-11 12:06:00 46\n",
      "\n",
      " 2019-10-15 16:06:00 31\n",
      "\n",
      " 2019-10-19 20:06:00 44\n",
      "\n",
      " 2019-10-24 00:06:00 39\n",
      "\n",
      " 2019-10-28 04:06:00 55\n",
      "\n",
      " 2019-11-01 08:06:00 51\n",
      "\n",
      " 2019-11-05 12:06:00 39\n",
      "\n",
      " 2019-11-09 16:06:00 60\n",
      "\n",
      " 2019-11-13 20:06:00 31\n",
      "\n",
      " 2019-11-18 00:06:00 49\n",
      "\n",
      " 2019-11-22 04:06:00 46\n",
      "\n",
      " 2019-11-26 08:06:00 43\n",
      "\n",
      " 2019-11-30 12:06:00 31\n",
      "\n",
      " 2019-12-04 16:06:00 57\n",
      "\n",
      " 2019-12-08 20:06:00 70\n",
      "\n",
      " 2019-12-13 00:06:00 52\n",
      "\n",
      " 2019-12-17 04:06:00 39\n",
      "\n",
      " 2019-12-21 08:06:00 57\n",
      "\n",
      " 2019-12-25 12:06:00 59\n",
      "\n",
      " 2019-12-29 16:06:00 84\n",
      "\n",
      " 2020-01-02 20:06:00 62\n",
      "\n",
      " 2020-01-07 00:06:00 55\n",
      "\n",
      " 2020-01-11 04:06:00 51\n",
      "\n",
      " 2020-01-15 08:06:00 35\n",
      "\n",
      " 2020-01-19 12:06:00 37\n",
      "\n",
      " 2020-01-23 16:06:00 49\n",
      "\n",
      " 2020-01-27 20:06:00 45\n",
      "\n",
      " 2020-02-01 00:06:00 41\n",
      "\n",
      " 2020-02-05 04:06:00 67\n",
      "\n",
      " 2020-02-09 08:06:00 57\n",
      "\n",
      " 2020-02-13 12:06:00 33\n",
      "\n",
      " 2020-02-17 16:06:00 53\n",
      "\n",
      " 2020-02-21 20:06:00 36\n",
      "\n",
      " 2020-02-26 00:06:00 65\n",
      "\n",
      " 2020-03-01 04:06:00 55\n",
      "\n",
      " 2020-03-05 08:06:00 55\n",
      "\n",
      " 2020-03-09 12:06:00 68\n",
      "\n",
      " 2020-03-13 16:06:00 39\n",
      "\n",
      " 2020-03-17 20:06:00 63\n",
      "\n",
      " 2020-03-22 00:06:00 71\n",
      "\n",
      " 2020-03-26 04:06:00 119\n",
      "\n",
      " 2020-03-30 08:06:00 62\n",
      "\n",
      " 2020-04-03 12:06:00 33\n",
      "\n",
      " 2020-04-07 16:06:00 42\n",
      "\n",
      " 2020-04-11 20:06:00 63\n",
      "\n",
      " 2020-04-16 00:06:00 40\n",
      "\n",
      " 2020-04-20 04:06:00 72\n",
      "\n",
      " 2020-04-24 08:06:00 76\n",
      "\n",
      " 2020-04-28 12:06:00 47\n",
      "\n",
      " 2020-05-02 16:06:00 71\n",
      "\n",
      " 2020-05-06 20:06:00 47\n",
      "\n",
      " 2020-05-11 00:06:00 81\n",
      "\n",
      " 2020-05-15 04:06:00 46\n",
      "\n",
      " 2020-05-19 08:06:00 31\n",
      "\n",
      " 2020-05-23 12:06:00 62\n",
      "\n",
      " 2020-05-27 16:06:00 68\n",
      "\n",
      " 2020-05-31 20:06:00 100\n",
      "\n",
      " 2020-06-05 00:06:00 49\n",
      "\n",
      " 2020-06-09 04:06:00 62\n",
      "\n",
      " 2020-06-13 08:06:00 44\n",
      "\n",
      " 2020-06-17 12:06:00 71\n",
      "\n",
      " 2020-06-21 16:06:00 63\n",
      "\n",
      " 2020-06-25 20:06:00 56\n",
      "\n",
      " 2020-06-30 00:06:00 48\n",
      "\n",
      " 2020-07-04 04:06:00 61\n",
      "\n",
      " 2020-07-08 08:06:00 41\n",
      "\n",
      " 2020-07-12 12:06:00 53\n",
      "\n",
      " 2020-07-16 16:06:00 48\n",
      "\n",
      " 2020-07-20 20:06:00 47\n",
      "\n",
      " 2020-07-25 00:06:00 29\n",
      "\n",
      " 2020-07-29 04:06:00 65\n",
      "\n",
      " 2020-08-02 08:06:00 58\n",
      "\n",
      " 2020-08-06 12:06:00 31\n",
      "\n",
      " 2020-08-10 16:06:00 65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AlertModel(data)\n",
    "\n",
    "model.iterateTo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
